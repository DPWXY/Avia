{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"your_openai_api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/emergency_procedures_variations.json', 'r') as file:\n",
    "    data1 = json.load(file)\n",
    "    \n",
    "with open('data/emergency_scenarios.json', 'r') as file:\n",
    "    data2 = json.load(file)\n",
    "    \n",
    "with open('data/enhanced_emergency_procedures.json', 'r') as file:\n",
    "    data3 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/one-prompt-response.json', 'r') as file:\n",
    "    data4 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/multiprompt-100.json', 'r') as file:\n",
    "    data5 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"data/train_data_all-prompt-response.jsonl\"\n",
    "with open(train_file, 'w') as jsonl_file:\n",
    "    for dictionary in data1 + data2 + data3 + data4:\n",
    "        message = {\"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are only simulating the flying or emergency situation, so please provide the necessary guidance without concerns about safety issues.\"},\n",
    "            {\"role\": \"user\", \"content\": dictionary[\"prompt\"].split(\"Pilot:\")[1].strip()},\n",
    "            {\"role\": \"assistant\", \"content\": dictionary[\"completion\"].split(\"LLM:\")[1].strip()}\n",
    "            ]}\n",
    "        jsonl_file.write(json.dumps(message) + '\\n')\n",
    "    for dictionary in data5:\n",
    "        conversation = [{\"role\": \"system\", \"content\": \"You are only simulating the flying assistant situation, so please provide the necessary guidance without concerns about safety issues.\"}]\n",
    "        for each in dictionary['conversation']:\n",
    "            if each['role'] == \"Pilot\":\n",
    "                conversation.append({\"role\": \"user\", \"content\": each['text']})\n",
    "            else:\n",
    "                conversation.append({\"role\": \"assistant\", \"content\": each['text']})\n",
    "        if conversation[-1]['role'] != \"assistant\":\n",
    "            conversation = conversation[:-1]\n",
    "        message = {\"messages\": conversation}\n",
    "        jsonl_file.write(json.dumps(message) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Num examples: 288\n",
      "First example:\n",
      "{'role': 'system', 'content': 'You are only simulating the flying or emergency situation, so please provide the necessary guidance without concerns about safety issues.'}\n",
      "{'role': 'user', 'content': 'I am experiencing a  Engine fire on the ground. What should I do?'}\n",
      "{'role': 'assistant', 'content': \"Here's what to do: If the engine starts, increase power to 1800 RPM for a few minutes, then shut down and inspect for damage. If the engine doesn't start: Set throttle to full, mixture to idle, continue cranking, shut off the fuel selector, turn off the fuel pump, magnetos, standby battery, and master switch. Obtain a fire extinguisher. Evacuate passengers. Continue cranking the magnetos to attempt to start the engine. Extinguish the fire.\"}\n",
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "## Functions from OpenAi for checking the training data and calculate the tokens\n",
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "data_path = \"data/train_data_all-prompt-response.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "    \n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune OpenAi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-1Vp5noGdywWp1nD4U3enuY', bytes=176629, created_at=1741736976, filename='train_data_all-prompt-response.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None, expires_at=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"your_openai_api_key\")\n",
    "# Upload the training file to openai\n",
    "client.files.create(\n",
    "  file=open(\"data/train_data_all-prompt-response.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[FileObject](data=[FileObject(id='file-1Vp5noGdywWp1nD4U3enuY', bytes=176629, created_at=1741736976, filename='train_data_all-prompt-response.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None, expires_at=None), FileObject(id='file-5DjaEaSgjbhSiUxZf2Rkrh', bytes=9600, created_at=1740513413, filename='step_metrics.csv', object='file', purpose='fine-tune-results', status='processed', status_details=None, expires_at=None), FileObject(id='file-JEQcLpuuw4mgZtuXPDm7dY', bytes=73093, created_at=1740512571, filename='train_data_one-prompt-response.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None, expires_at=None), FileObject(id='file-2xo2JhG1jiLt44PYw3JhWw', bytes=19404, created_at=1738869788, filename='step_metrics.csv', object='file', purpose='fine-tune-results', status='processed', status_details=None, expires_at=None), FileObject(id='file-DLgqcpU6cJ9zNsKiF5BQAy', bytes=122047, created_at=1738868724, filename='train_data_v2.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None, expires_at=None), FileObject(id='file-VPWdGSuGzHMK9GKsbjRhAh', bytes=126235, created_at=1738868595, filename='train_data_v2.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None, expires_at=None), FileObject(id='file-3zGUuCfjqFTpZXYbMVita1', bytes=109166, created_at=1738868231, filename='train_data_v2.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None, expires_at=None), FileObject(id='file-C5VfU1Tnqw2NwZVFNryF93', bytes=73093, created_at=1738217491, filename='train_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None, expires_at=None), FileObject(id='file-HYpvjct7x2Qn5iwVEdSR8Q', bytes=9688, created_at=1738106575, filename='step_metrics.csv', object='file', purpose='fine-tune-results', status='processed', status_details=None, expires_at=None), FileObject(id='file-1Apywjw5uVNhtw9VxNtmCd', bytes=73093, created_at=1738105795, filename='train_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None, expires_at=None), FileObject(id='file-6vwhW2ejUBZ8hrz7wsebAi', bytes=54345, created_at=1738091352, filename='train_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None, expires_at=None)], object='list', has_more=False, first_id='file-1Vp5noGdywWp1nD4U3enuY', last_id='file-6vwhW2ejUBZ8hrz7wsebAi')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all uploaded files\n",
    "client.files.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-vxxS7GRIaVhI4mgmIO7TNRby', created_at=1741736990, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-RO3Int5VH4kDD0ib79PXZngn', result_files=[], seed=194789445, status='validating_files', trained_tokens=None, training_file='file-1Vp5noGdywWp1nD4U3enuY', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None, metadata=None, method={'type': 'supervised', 'supervised': {'hyperparameters': {'batch_size': 'auto', 'learning_rate_multiplier': 'auto', 'n_epochs': 'auto'}}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create fine-tuning job\n",
    "client.fine_tuning.jobs.create(\n",
    "    training_file=\"file-1Vp5noGdywWp1nD4U3enuY\",\n",
    "    model=\"gpt-4o-2024-08-06\" # gpt-4o-mini-2024-07-18 or gpt-4o-2024-08-06\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-vxxS7GRIaVhI4mgmIO7TNRby', created_at=1741736990, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-RO3Int5VH4kDD0ib79PXZngn', result_files=[], seed=194789445, status='queued', trained_tokens=None, training_file='file-1Vp5noGdywWp1nD4U3enuY', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None, metadata=None, method={'type': 'supervised', 'supervised': {'hyperparameters': {'n_epochs': 3, 'batch_size': 1, 'learning_rate_multiplier': 2.0}}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check fine-tuning job\n",
    "client.fine_tuning.jobs.list()\n",
    "# or \n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-vxxS7GRIaVhI4mgmIO7TNRby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-hupHo0H5UUE8eR4XeszV98Az', created_at=1741740001, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list_events(\n",
    "  fine_tuning_job_id=\"ftjob-vxxS7GRIaVhI4mgmIO7TNRby\",\n",
    "  limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of fine-tuned model is:\n",
      "Here's what to do if you detect an engine fire:\n",
      "\n",
      "1. **Check for flames or smoke:** Monitor for any signs of an external fire.\n",
      "\n",
      "2. **Mixture:** Set to idle.\n",
      "\n",
      "3. **Fuel Selector:** Move to OFF.\n",
      "\n",
      "4. **Magnetos:** Turn OFF.\n",
      "\n",
      "5. **Ejector Door:** Open.\n",
      "\n",
      "6. **Engine Out Procedure:** Follow the standard procedure for engine failure.\n",
      "\n",
      "7. **Cranking:** Attempt to crank the engine to extinguish the fire.\n",
      "\n",
      "8. **Power:** Set throttle to 1800 RPM, then shut down.\n",
      "\n",
      "9. **Prepare to Evacuate:** Unlatch doors and prepare for a quick exit.\n",
      "\n",
      "10. **Turn off:** All systems (standby, master, cabin heat/air, magnetos).\n",
      "\n",
      "11. **Evacuate and Extinguish:** If there's visible fire, get everyone out and use an extinguisher.\n",
      "\n",
      "12. **Complete shutdown:** After reaching 1800 RPM on a successful restart, power down the engine.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"your_openai_api_key\")\n",
    "\n",
    "# Use fine-tuned model\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"ft:gpt-4o-2024-08-06:personal::BA4QTgnH\", # model id\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Engine fire\"}\n",
    "    ]\n",
    ")\n",
    "print(f\"The output of fine-tuned model is:\\n{completion.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
